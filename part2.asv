function [ transforms, objects ] = part2( imglistdepth,imglistrgb,cam_params )
%PARTE2 Summary of this function goes here
%inputs : imglistdepth -> Cell array with strings indicating the path of each depth image
%         imglistrgb   -> Cell array with strings indicating the path of each rgb image
%         cam_params   -> Struct with instrinsic and extrinsic camera parameters.
%                         cam_params.Kdepth  - the 3x3 matrix for the intrinsic parameters for depth
%                         cam_params.Krgb - the 3x3 matrix for the intrinsic parameters for rgb
%                         cam_params.R - the Rotation matrix from depth to RGB (extrinsic params)
%                         cam_params.T - The translation from depth to RGB
%This is also like you did in the lab, except that everything is in one structure. For example,
%cam_params.R should be Rdtorgb that you use in the lab
%outputs : transforms  -> 
%                         transfomrs{i}.R - the 3x3  roation matrix between image i  and image 1
%                         transforms{i}.T - the 3x1 translation vector  between image i and image 1 mW.T

%H=estimate_homografy(imglistrgb(1),imglistrgb(2));
n=length(imglistdepth);
H{1}= eye(4);
for i=2:n
    if (i==2)
        I1= imread(imglistrgb{i-1});
        [f1,d1] = vl_sift(single(rgb2gray(I1)));
        load(imglistdepth{i-1});
        depth_array_1=depth_array;
    else
        I1=I2;
        f1=f2;
        d1=d2;
        depth_array_1=depth_array_2;
    end
    I2= imread(imglistrgb{i});
    [f2,d2] = vl_sift(single(rgb2gray(I2))) ;
    load(imglistdepth{i});
    depth_array_2=depth_array;
    [matches, scores] = vl_ubcmatch(d1, d2);
    
    points_1= f1(1:2,matches(1,:)) ;
    depth_array_1(isnan(depth_array_1))=0;
    xyz_I1= position3(cam_params.Kdepth,cam_params.Krgb,cam_params.R,cam_params.T,depth_array_1,floor(points_1));
    
    depth_array_2(isnan(depth_array_2))=0;
    points_2=f2(1:2,matches(2,:));
    xyz_I2= position3(cam_params.Kdepth,cam_params.Krgb,cam_params.R,cam_params.T,depth_array_2,floor(points_2));
    
    % Ransac
    %returns indexes of the inliers in the vector matches (which indexes all the features)  
    inliers=ransac_3dtransformation(xyz_I1,xyz_I2);
    
    %update points to calculate the transformation
    xyz_I1=xyz_I1(:,inliers) ;
    xyz_I2=xyz_I2(:,inliers);
    %centroid calculations
    c_1=nanmean(xyz_I1,2);
    c_2=nanmean(xyz_I2,2);
    %pushing the centroids to the origin
    xyz_I1=bsxfun(@(a,b) a-b,xyz_I1,c_1);
    xyz_I2=bsxfun(@(a,b) a-b,xyz_I2,c_2);
    %remove nan from data
    xyz_I1(:,~all(~isnan(xyz_I1)))=[];
    xyz_I2(:,~all(~isnan(xyz_I2)))=[];


    E=xyz_I2*(xyz_I1)';

    [U,S,V]=svd(E);
    R=V*U';
    t=c_1-R*c_2;

    H{i}= [R t;0 0 0 1];
    transforms{i}=eye(4);
    for j=i:-1:1
        transforms{i}=H{j}*transforms{i};
    end
end

%transforms=H;
objects=[];
end

